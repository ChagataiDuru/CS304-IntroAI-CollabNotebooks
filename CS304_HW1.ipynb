{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChagataiDuru/CS304-IntroAI-CollabNotebooks/blob/main/CS304_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1\n",
        "If you have any questions please send an email to the TA Ahmet Tavlı (ahmet.tavli@ozu.edu.tr) (Office hours: Monday 245A 16.00 - 18.00)"
      ],
      "metadata": {
        "id": "fJ6VKhyaYtFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load and analyze the data"
      ],
      "metadata": {
        "id": "Y8leBJU3Y1j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.a Load the two datasets ##"
      ],
      "metadata": {
        "id": "Jd98xnxdZLxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's check whether the training and the test files exist in our file.\n",
        "from os.path import exists\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data = \"/content/drive/MyDrive/Colab Notebooks/CS304/HW1/titanictrain.csv\"\n",
        "test_data = \"/content/drive/MyDrive/Colab Notebooks/CS304/HW1/titanictest.csv\"\n",
        "\n",
        "# - Supress all warnings (Optional)\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore',\n",
        "                      category=FutureWarning)\n",
        "\n",
        "if exists(train_data) and exists(test_data):\n",
        "    print(f\"\\nBoth {train_data} and {test_data} exists.\")\n",
        "else:\n",
        "    print(\"Please set directory to read the files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etgUS4qkZV_M",
        "outputId": "0f45c33a-0f40-47a7-bc3c-e7268a366ad9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Both /content/drive/MyDrive/Colab Notebooks/CS304/HW1/titanictrain.csv and /content/drive/MyDrive/Colab Notebooks/CS304/HW1/titanictest.csv exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the training and the test data and display their types.\n",
        "# Hint!: you can use the read_csv from pandas and type built-in method\n",
        "\n",
        "from pandas import read_csv\n",
        "\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "\n",
        "# Load the datasets\n",
        "train_df = read_csv(train_data)\n",
        "test_df = read_csv(test_data)\n",
        "#  -------------------\n"
      ],
      "metadata": {
        "id": "62Qrfxysc94Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1.b Display the shape of both training and test data.##\n",
        "\n",
        "The shape of each data shows a summary of the dataset.\n",
        "\n",
        "For example, \"(890, 12)\" should be interpreted as 890 samples with ten features, where\n",
        "\n",
        "890 is the row size (or height of the data)\n",
        "12 is the column size (or width of the data)\n",
        "\n",
        "**Hint!**: You can use the shape method"
      ],
      "metadata": {
        "id": "VY4uYP36as9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "# Shapes of datasets\n",
        "print(\"Training set shape:\", train_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)\n",
        "#  ---------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVD10G-da5wq",
        "outputId": "f3f8df14-57a2-406b-bfff-c5df216d4985"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (891, 12)\n",
            "Test set shape: (418, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.c Display the first five rows of training and test data ##"
      ],
      "metadata": {
        "id": "YhJBvWaVbOOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here to display training data\n",
        "#  -------------------\n",
        "print(\"\\nTraining set (first 5 rows):\\n\", train_df.head())\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-UKcJbzbX7s",
        "outputId": "50c28156-4ed8-4bc3-a311-dc1ae5d7a931"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set (first 5 rows):\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here to display test data\n",
        "#  -------------------\n",
        "print(\"\\nTest set (first 5 rows):\\n\", test_df.head())\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XsWGA9ScC7d",
        "outputId": "1c4d215c-2ce0-41de-d98b-5bd250744e20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set (first 5 rows):\n",
            "    PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.e Determine which column exists in the training set but is missing in the test set ##\n",
        "\n",
        "Training and test sets have different number of features (columns).\n",
        "\n",
        "In Step 1.b you saw that the traind_df has 12 columns bur test_df has 11 columns\n",
        "\n",
        "We need to find which column is missing in the test data.\n",
        "\n",
        "**Hint!**: You can access the features using keys method.\n",
        "\n",
        "**Hint!**: Iterate through the keys of training samples, and check if it is in the set of test features."
      ],
      "metadata": {
        "id": "wN1m7mFIcRnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "#  Missing column in test set\n",
        "missing_col = set(train_df.columns) - set(test_df.columns)\n",
        "print(\"\\nColumn missing in test set:\", missing_col)\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w65srsaRcp_X",
        "outputId": "b9663321-fed7-4725-cf60-456623f2b7d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column missing in test set: {'Survived'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.f Observe the datatype of each column using the .info() method ##"
      ],
      "metadata": {
        "id": "ZV1vKKICdkAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect training data\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "#  Data types and summary statistics\n",
        "print(\"\\nTraining set info:\\n\", train_df.info())\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fN05Npcb1D",
        "outputId": "4025088f-66d8-4ffe-9de6-3d5f52db9f74"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "Training set info:\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describe the statistics of numerical attribures of training set\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "print(\"\\nTraining set numerical descriptions:\\n\", train_df.describe())\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cTgOXSp4Bpg",
        "outputId": "9d0c207f-5458-4450-bdbf-097014ee06f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set numerical descriptions:\n",
            "        PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect test data\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "print(\"\\Test set info:\\n\", test_df.info())\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqZrrtdSeFVF",
        "outputId": "d0010288-a8ce-4f73-d840-1e4bd9d9e5c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "\\Test set info:\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.g. Determine the number and percentage of passengers who survived. ##"
      ],
      "metadata": {
        "id": "VaxTo5w95NCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "#  Survival statistics\n",
        "survived = train_df['Survived'].value_counts()\n",
        "percent_survived = survived[1] / len(train_df) * 100\n",
        "\n",
        "print(\"\\nNumber of survived passengers:\", survived[1])\n",
        "print(\"Percentage of survived passengers:\", percent_survived)\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "WuQh3eYg5bPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565c29cb-fb6e-4977-91a7-993accf657da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of survived passengers: 342\n",
            "Percentage of survived passengers: 38.38383838383838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Prepare the data for classification #"
      ],
      "metadata": {
        "id": "g6um65U-eOAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.a Extract the target label (i.e. \"Survived\") from the training set and assign it to the variable \"y_train\" ##"
      ],
      "metadata": {
        "id": "X-sKWApUerYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "y_train = train_df[\"Survived\"]\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "29j5V3vBeZO5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.b Copy the columns \"Pclass\",\"Sex\", \"Age\", \"Fare\" to a new dataframe##\n",
        "\n",
        "Name the new dataframe as x_train\n",
        "Display the top 5 rows of x_train"
      ],
      "metadata": {
        "id": "sdUZ9oO-elxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
        "X_train = train_df[features]\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "Wp2EB79zhDFS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.c Add a new feature \"FamilySize\" ##\n",
        "\n",
        "\"Sibsp\" and \"Parch\" features are related.\n",
        "\n",
        "Instead of using them separately, we can use their sum as a feature.\n",
        "\n",
        "**Hint!**: We can add the sum as a new column to the new data frame object as new_df['FamilySize'] = Sibsp + Parch\n",
        "\n",
        "**Hint!:** We can also limit the sum so that it does not exceed 4. (For this purpose one option is use the apply method.)\n",
        "\n",
        "Display the first five rows of x_train"
      ],
      "metadata": {
        "id": "lvyUaPeYiV5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "X_train[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]\n",
        "X_train[\"FamilySize\"] = X_train[\"FamilySize\"].clip(upper=4)  # Limit family size to 4\n",
        "#  -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo9p6R_cied4",
        "outputId": "ee90a03e-dc13-43bc-99cf-a0f7a508e84f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-048a2f32aba9>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]\n",
            "<ipython-input-30-048a2f32aba9>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train[\"FamilySize\"] = X_train[\"FamilySize\"].clip(upper=4)  # Limit family size to 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.g. Use a pipeline to implement Steps 2.d,e,f. OR implement them one-by-one. ##  "
      ],
      "metadata": {
        "id": "J2CNoc_5pCvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"impute\", SimpleImputer (by=[\"Sex\", \"Pclass\"])),\n",
        "    (\"encode\", LabelEncoder()),\n",
        "    (\"scale\", StandardScaler())\n",
        "])\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "BUXsVpwIlnKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "51934eb5-b7a8-4dd0-b399-9761b5a54564"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SimpleImputer.__init__() got an unexpected keyword argument 'by'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-56840aeba096>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m pipeline = Pipeline([\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"impute\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"encode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SimpleImputer.__init__() got an unexpected keyword argument 'by'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Train two different ML models and compare their accuracies #"
      ],
      "metadata": {
        "id": "FT78fCPrqHkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.a Split into training and test set, ratio: 80/20 ##"
      ],
      "metadata": {
        "id": "kTtxb5WZqO-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "5zbrzcrQqAlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "68rT6jJy0ltg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.b Train a logistic regression classifier and test the accuracy ##"
      ],
      "metadata": {
        "id": "s7AyGkXUrIYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_split, y_train_split)\n",
        "y_pred_lr = log_reg.predict(X_test_split)\n",
        "\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test_split, y_pred_lr)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "N4tjDGoYrPJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.c Train a random forest classifier and test the accuracy ##"
      ],
      "metadata": {
        "id": "hyEBWWcoyQbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from numpy import ravel\n",
        "\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_split, y_train_split)\n",
        "y_pred_rf = rf_model.predict(X_test_split)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test_split, y_pred_rf)\n",
        "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
        "\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "4dHYO6TZyUY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gy6Eu67DF7ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.d Train a logistic regression classifier using 5-fold cross validation. ##"
      ],
      "metadata": {
        "id": "Ke6jxkIaoukw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#  Add your code here\n",
        "#  -------------------\n",
        "\n",
        "# Logistic Regression with Cross-Validation\n",
        "scores_lr = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
        "print(\"Logistic Regression Cross-Validation Mean Accuracy:\", scores_lr.mean())\n",
        "print(\"Logistic Regression Cross-validation Standard Deviation:\", scores_lr.std())\n",
        "\n",
        "\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "7BHv1aWto37M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.e Train a random forest classifier using 5-fold cross validation."
      ],
      "metadata": {
        "id": "ItJWPpvkrATp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add your code here\n",
        "#  -------------------\n",
        "\n",
        "# Random Forest with Cross-Validation\n",
        "scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
        "print(\"Random Forest Cross-Validation Mean Accuracy:\", scores_rf.mean())\n",
        "print(\"Random Forest Cross-validation Standard Deviation:\", scores_rf.std())\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "pizUclZvq_RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.f Inspect the confusion matrices of the two classifiers ##"
      ],
      "metadata": {
        "id": "UvEto6q3uqco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "#  Add your code  here\n",
        "#  -------------------\n",
        "\n",
        "cm_lr = confusion_matrix(y_test_split, y_pred_lr)\n",
        "cm_rf = confusion_matrix(y_test_split, y_pred_rf)\n",
        "\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "DGOv-w-Ruw8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.g Calculate the precision and recall scores of the two classifiers ##"
      ],
      "metadata": {
        "id": "-fC1TyNPzZ4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "#  Add your code  here\n",
        "#  -------------------\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Precision:\", precision_score(y_test_split, y_pred_lr))\n",
        "print(\"Recall:\", recall_score(y_test_split, y_pred_lr))\n",
        "print(\"F1-Score:\", f1_score(y_test_split, y_pred_lr))\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "print(\"Precision:\", precision_score(y_test_split, y_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_test_split, y_pred_rf))\n",
        "print(\"F1-Score:\", f1_score(y_test_split, y_pred_rf))\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "9MgpqMFqzmcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.h Draw the precision-recall curves of the two classifiers. ##"
      ],
      "metadata": {
        "id": "jEk3IR6o8SJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "#  Add your code  here\n",
        "#  -------------------\n",
        "\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "I_f02CRh1_wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.h. Draw the ROC curves for the two classifiers and comment. ##"
      ],
      "metadata": {
        "id": "hYOlwfNL1TOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#  Add your code  here\n",
        "#  -------------------\n",
        "\n",
        "#  -------------------"
      ],
      "metadata": {
        "id": "xLFzcUQG1kjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 Comments ##\n",
        "a. Which classifiers gave better results? Explain\n",
        "\n",
        "\n",
        "b. Which data imputation method gave better results?\n",
        "\n",
        "\n",
        "c. How can you further improve the performance?"
      ],
      "metadata": {
        "id": "uRapX1XeyxJe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmuEvw1d2Ujm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}